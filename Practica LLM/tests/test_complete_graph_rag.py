#!/usr/bin/env python3
"""
Test Completo Microsoft Graph RAG Pipeline
==========================================

Demuestra el pipeline completo de Graph RAG integrado con el sistema existente.
"""

import sys
import os
import time
import json
from pathlib import Path

# Setup path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_complete_graph_rag_pipeline():
    """Test del pipeline completo de Graph RAG"""
    
    print("üöÄ MICROSOFT GRAPH RAG - PIPELINE COMPLETO")
    print("=" * 60)
    
    try:
        from rag_preprocessing.graph_rag.pipeline import GraphRAGPipeline, GraphRAGConfig
        
        # Configurar pipeline
        config = GraphRAGConfig(
            max_community_levels=3,
            min_community_size=2,
            use_llm_extraction=False,  # Solo spaCy por ahora
            community_algorithm="leiden"
        )
        
        # Crear pipeline
        pipeline = GraphRAGPipeline(config)
        
        print(f"‚úÖ Pipeline inicializado con configuraci√≥n:")
        print(f"   - Algoritmo: {config.community_algorithm}")
        print(f"   - Niveles m√°ximos: {config.max_community_levels}")
        print(f"   - Tama√±o m√≠nimo comunidad: {config.min_community_size}")
        print(f"   - LLM Extraction: {config.use_llm_extraction}")
        
        # Documentos de prueba m√°s complejos
        test_documents = [
            """
            Microsoft Research desarroll√≥ Graph RAG en colaboraci√≥n con OpenAI y Stanford University. 
            El proyecto utiliza algoritmos de detecci√≥n de comunidades como Leiden y Louvain para 
            identificar clusters de entidades relacionadas. NetworkX proporciona la infraestructura 
            base para manipulaci√≥n de grafos, mientras que igraph ofrece implementaciones m√°s eficientes.
            
            El Dr. Garc√≠a de la Universidad de Madrid lidera la investigaci√≥n en sistemas RAG h√≠bridos.
            Su equipo colabora con investigadores de MIT, Stanford y Google DeepMind en el desarrollo
            de arquitecturas de embedding vectorial. Los algoritmos de quantizaci√≥n vectorial mejoran 
            la eficiencia del almacenamiento en sistemas como ChromaDB y Qdrant.
            
            El enfoque de Microsoft combina b√∫squeda local en comunidades espec√≠ficas con b√∫squeda 
            global en res√∫menes jer√°rquicos. Esto permite responder tanto preguntas espec√≠ficas 
            sobre entidades individuales como preguntas amplias sobre tendencias y patrones generales.
            """
        ]
        
        # 1. Procesar documentos
        print(f"\nüìÑ PROCESANDO DOCUMENTOS...")
        print(f"   Documentos: {len(test_documents)}")
        print(f"   Longitud total: {sum(len(doc) for doc in test_documents):,} caracteres")
        
        start_time = time.time()
        result = pipeline.process_documents(test_documents)
        processing_time = time.time() - start_time
        
        print(f"‚úÖ Procesamiento completado en {processing_time:.2f}s")
        print(f"\nüìä RESULTADOS DEL PROCESAMIENTO:")
        print(f"   üè∑Ô∏è  Entidades extra√≠das: {result['entities']}")
        print(f"   üîó Relaciones detectadas: {result['relationships']}")
        print(f"   üï∏Ô∏è  Comunidades detectadas: {result['communities']}")
        print(f"   üìä Niveles jer√°rquicos: {result['levels']}")
        print(f"   üìù Reportes generados: {result['reports']}")
        print(f"   ‚è±Ô∏è  Tiempo de procesamiento: {result['processing_time']:.3f}s")
        print(f"   ‚úÖ Estado: {result['status']}")
        
        # 2. Test de consultas
        print(f"\nüîç TESTING CONSULTAS GRAPH RAG...")
        
        test_queries = [
            "¬øQu√© algoritmos usa Microsoft Graph RAG?",
            "¬øQui√©n colabora con la Universidad de Madrid?",
            "¬øC√≥mo funciona la b√∫squeda h√≠brida en Graph RAG?"
        ]
        
        for i, query in enumerate(test_queries, 1):
            print(f"\nüìù CONSULTA {i}: {query}")
            
            # Test b√∫squeda local
            local_result = pipeline.query(query, search_type="local")
            print(f"   üè† Local: {local_result['answer'][:100]}...")
            print(f"      Confidence: {local_result['confidence']:.2f}")
            
            # Test b√∫squeda global
            global_result = pipeline.query(query, search_type="global")
            print(f"   üåç Global: {global_result['answer'][:100]}...")
            print(f"      Confidence: {global_result['confidence']:.2f}")
            
            # Test b√∫squeda h√≠brida
            hybrid_result = pipeline.query(query, search_type="hybrid")
            print(f"   üîÄ Hybrid: {hybrid_result['answer'][:100]}...")
            print(f"      Confidence: {hybrid_result['confidence']:.2f}")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR EN PIPELINE: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_graph_rag_integration():
    """Test de integraci√≥n con el sistema RAG principal"""
    
    print(f"\n\nüîó TESTING INTEGRACI√ìN CON SISTEMA RAG PRINCIPAL")
    print("=" * 60)
    
    try:
        # Importar sistema RAG principal
        from rag_preprocessing import get_document_processor, get_vector_store
        from rag_preprocessing.graph_rag.pipeline import GraphRAGPipeline
        
        # Inicializar componentes
        vector_processor = get_document_processor()
        vector_store = get_vector_store()
        graph_pipeline = GraphRAGPipeline()
        
        # Documento de prueba
        test_text = """
        El Graph RAG de Microsoft revoluciona la b√∫squeda en documentos al combinar 
        embeddings vectoriales con an√°lisis de grafos de conocimiento. El sistema 
        detecta autom√°ticamente entidades como organizaciones, personas y conceptos,
        luego identifica comunidades de entidades relacionadas usando el algoritmo Leiden.
        """
        
        print(f"üìÑ Procesando documento h√≠brido...")
        print(f"   Texto: {test_text[:100]}...")
        
        # 1. Procesamiento vectorial tradicional
        print(f"\nüî¢ PROCESAMIENTO VECTORIAL:")
        vector_start = time.time()
        vector_result = vector_processor.process_text(
            text=test_text,
            document_id="hybrid_test_doc",
            metadata={"type": "hybrid_test"}
        )
        vector_time = time.time() - vector_start
        
        print(f"   ‚úÖ Chunks: {vector_result.chunks_processed}")
        print(f"   ‚úÖ Embeddings: {vector_result.embeddings_created}")
        print(f"   ‚è±Ô∏è  Tiempo: {vector_time:.3f}s")
        
        # 2. Procesamiento Graph RAG
        print(f"\nüï∏Ô∏è  PROCESAMIENTO GRAPH RAG:")
        graph_start = time.time()
        graph_result = graph_pipeline.process_documents([test_text])
        graph_time = time.time() - graph_start
        
        print(f"   ‚úÖ Entidades: {graph_result['entities']}")
        print(f"   ‚úÖ Comunidades: {graph_result['communities']}")
        print(f"   ‚è±Ô∏è  Tiempo: {graph_time:.3f}s")
        
        # 3. B√∫squeda h√≠brida simulada
        print(f"\nüîç B√öSQUEDA H√çBRIDA SIMULADA:")
        query = "¬øC√≥mo funciona Graph RAG?"
        
        # B√∫squeda vectorial
        vector_search_start = time.time()
        # Generar embedding de consulta
        query_embedding = vector_processor.embedding_manager.encode(query)
        vector_search_results = vector_store.search(
            query_embedding=query_embedding.embeddings[0],
            k=3
        )
        vector_search_time = time.time() - vector_search_start
        
        print(f"   üî¢ Vector Search: {len(vector_search_results)} resultados en {vector_search_time*1000:.1f}ms")
        if vector_search_results:
            print(f"      Mejor score: {vector_search_results[0].score:.3f}")
        
        # B√∫squeda Graph RAG
        graph_search_start = time.time()
        graph_search_result = graph_pipeline.query(query, search_type="hybrid")
        graph_search_time = time.time() - graph_search_start
        
        print(f"   üï∏Ô∏è  Graph Search: respuesta en {graph_search_time*1000:.1f}ms")
        print(f"      Confidence: {graph_search_result['confidence']:.2f}")
        
        # M√©tricas comparativas
        print(f"\nüìä M√âTRICAS COMPARATIVAS:")
        print(f"   Procesamiento Vector: {vector_time:.3f}s")
        print(f"   Procesamiento Graph: {graph_time:.3f}s")
        print(f"   B√∫squeda Vector: {vector_search_time*1000:.1f}ms")
        print(f"   B√∫squeda Graph: {graph_search_time*1000:.1f}ms")
        
        total_processing = vector_time + graph_time
        print(f"   üìà Procesamiento H√≠brido Total: {total_processing:.3f}s")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR EN INTEGRACI√ìN: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Funci√≥n principal"""
    
    print("üß™ MICROSOFT GRAPH RAG - TEST COMPLETO")
    print("=" * 70)
    
    # Test 1: Pipeline completo
    success1 = test_complete_graph_rag_pipeline()
    
    # Test 2: Integraci√≥n con sistema principal
    success2 = test_graph_rag_integration()
    
    # Resultado final
    print("\n" + "=" * 70)
    if success1 and success2:
        print("üéâ TODOS LOS TESTS COMPLETADOS EXITOSAMENTE")
        print("‚úÖ Graph RAG Pipeline: PASS")
        print("‚úÖ Integraci√≥n H√≠brida: PASS")
        print("\nüöÄ MICROSOFT GRAPH RAG SPRINT 2: 70% COMPLETADO")
        print("üìã Pr√≥ximos pasos: Community Summarization + LLM Integration")
    else:
        print("‚ùå ALGUNOS TESTS FALLARON")
        print(f"‚ùå Graph RAG Pipeline: {'PASS' if success1 else 'FAIL'}")
        print(f"‚ùå Integraci√≥n H√≠brida: {'PASS' if success2 else 'FAIL'}")

if __name__ == "__main__":
    main() 