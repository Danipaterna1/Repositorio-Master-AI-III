#!/usr/bin/env python3
"""
Test Microsoft Graph RAG Entity Extraction
==========================================

Script de prueba para verificar que el Entity Extractor funciona correctamente.
"""

import sys
import os
import logging
from pathlib import Path

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# A√±adir path para importar rag_preprocessing
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_entity_extraction():
    """Prueba la extracci√≥n de entidades con diferentes tipos de texto"""
    
    print("üîç TESTING MICROSOFT GRAPH RAG - ENTITY EXTRACTION")
    print("=" * 60)
    
    try:
        from rag_preprocessing.graph_rag.entity_extractor import EntityExtractor
        
        # Crear extractor
        extractor = EntityExtractor()
        
        # Textos de prueba
        test_texts = [
            {
                "name": "Texto Simple",
                "content": "Microsoft desarroll√≥ Graph RAG en colaboraci√≥n con OpenAI. El sistema usa algoritmos Leiden para detectar comunidades en grafos de conocimiento."
            },
            {
                "name": "Texto T√©cnico", 
                "content": "El algoritmo Leiden mejora el Louvain implementando optimizaci√≥n local y refinamiento. NetworkX proporciona la base para manipulaci√≥n de grafos mientras que igraph ofrece implementaciones m√°s eficientes."
            },
            {
                "name": "Texto Conversacional",
                "content": "Dr. Garc√≠a trabaja en la Universidad de Madrid desarrollando sistemas RAG. Su equipo colabora con investigadores de Stanford y MIT en proyectos de IA generativa."
            }
        ]
        
        # Procesar cada texto
        for i, test_case in enumerate(test_texts, 1):
            print(f"\nüìù TEST {i}: {test_case['name']}")
            print("-" * 40)
            print(f"Texto: {test_case['content'][:100]}...")
            
            # Extraer entidades
            result = extractor.extract_entities_and_relationships(
                text=test_case['content'],
                use_llm_fallback=False  # Solo spaCy por ahora
            )
            
            print(f"‚è±Ô∏è  Tiempo: {result.processing_time:.3f}s")
            print(f"üîß M√©todo: {result.method_used}")
            print(f"‚≠ê Confidence: {result.confidence_score:.2f}")
            print(f"üë• Entidades: {len(result.entities)}")
            print(f"üîó Relaciones: {len(result.relationships)}")
            
            # Mostrar entidades detectadas
            if result.entities:
                print("\nüè∑Ô∏è  ENTIDADES DETECTADAS:")
                for entity in result.entities[:5]:  # Mostrar solo las primeras 5
                    print(f"  ‚Ä¢ {entity.name} ({entity.type.value}) - Conf: {entity.confidence:.2f}")
            
            # Mostrar relaciones detectadas
            if result.relationships:
                print("\nüîó RELACIONES DETECTADAS:")
                for rel in result.relationships[:3]:  # Mostrar solo las primeras 3
                    print(f"  ‚Ä¢ {rel.source_entity_id} ‚Üí {rel.relation_type.value} ‚Üí {rel.target_entity_id}")
        
        # Mostrar m√©tricas finales
        print("\nüìä M√âTRICAS FINALES")
        print("=" * 30)
        metrics = extractor.get_extraction_metrics()
        
        for key, value in metrics.items():
            if isinstance(value, float):
                print(f"{key}: {value:.3f}")
            else:
                print(f"{key}: {value}")
        
        print("\n‚úÖ ENTITY EXTRACTION TEST COMPLETADO")
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR EN ENTITY EXTRACTION: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_community_detection():
    """Prueba r√°pida de detecci√≥n de comunidades"""
    
    print("\n\nüï∏Ô∏è  TESTING COMMUNITY DETECTION")
    print("=" * 40)
    
    try:
        from rag_preprocessing.graph_rag.entity_extractor import EntityExtractor
        from rag_preprocessing.graph_rag.community_detector import CommunityDetector
        
        # Crear extractores
        entity_extractor = EntityExtractor()
        community_detector = CommunityDetector()
        
        # Texto m√°s largo para generar m√°s entidades
        long_text = """
        Microsoft Research desarroll√≥ Graph RAG en colaboraci√≥n con OpenAI y Stanford University. 
        El proyecto utiliza algoritmos de detecci√≥n de comunidades como Leiden y Louvain.
        NetworkX proporciona la infraestructura base mientras que igraph ofrece implementaciones optimizadas.
        El Dr. Garc√≠a de la Universidad de Madrid lidera la investigaci√≥n en sistemas RAG h√≠bridos.
        Su equipo colabora con investigadores de MIT, Stanford y Google DeepMind.
        Los algoritmos de quantizaci√≥n vectorial mejoran la eficiencia del almacenamiento.
        ChromaDB se usa para desarrollo mientras que Qdrant escala a nivel de producci√≥n.
        """
        
        # 1. Extraer entidades y relaciones
        print("üìù Extrayendo entidades...")
        extraction_result = entity_extractor.extract_entities_and_relationships(long_text, use_llm_fallback=False)
        
        print(f"‚úÖ Extra√≠das {len(extraction_result.entities)} entidades y {len(extraction_result.relationships)} relaciones")
        
        # 2. Detectar comunidades
        print("üï∏Ô∏è  Detectando comunidades...")
        hierarchy = community_detector.detect_communities(
            entities=extraction_result.entities,
            relationships=extraction_result.relationships,
            max_levels=2,
            min_community_size=2
        )
        
        print(f"‚úÖ Detectadas comunidades en {hierarchy.total_levels} niveles")
        print(f"üìä Total de comunidades: {hierarchy.total_communities}")
        print(f"üîß Algoritmo usado: {hierarchy.detection_algorithm}")
        print(f"‚è±Ô∏è  Tiempo: {hierarchy.processing_time:.3f}s")
        
        # Mostrar comunidades por nivel
        for level in range(hierarchy.total_levels):
            communities = hierarchy.get_level_communities(level)
            print(f"\nüìë NIVEL {level}: {len(communities)} comunidades")
            
            for i, community in enumerate(communities):
                entity_names = []
                entity_map = {e.id: e.name for e in extraction_result.entities}
                
                for entity_id in list(community.entities)[:3]:  # Primeras 3 entidades
                    if entity_id in entity_map:
                        entity_names.append(entity_map[entity_id])
                
                print(f"  Comunidad {i}: {', '.join(entity_names)}... ({community.size} entidades)")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR EN COMMUNITY DETECTION: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("üöÄ INICIANDO TESTS DE MICROSOFT GRAPH RAG")
    print("=" * 70)
    
    # Test 1: Entity Extraction
    success1 = test_entity_extraction()
    
    # Test 2: Community Detection
    success2 = test_community_detection()
    
    # Resultado final
    print("\n" + "=" * 70)
    if success1 and success2:
        print("üéâ TODOS LOS TESTS COMPLETADOS EXITOSAMENTE")
        print("‚úÖ Entity Extraction: PASS")
        print("‚úÖ Community Detection: PASS")
        print("\nüöÄ Microsoft Graph RAG est√° listo para Sprint 2!")
    else:
        print("‚ùå ALGUNOS TESTS FALLARON")
        print(f"‚ùå Entity Extraction: {'PASS' if success1 else 'FAIL'}")
        print(f"‚ùå Community Detection: {'PASS' if success2 else 'FAIL'}") 