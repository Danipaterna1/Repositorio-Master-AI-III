# ğŸ“‹ PLAN TÃ‰CNICO - PREPROCESAMIENTO RAG

> **ğŸ‘‰ Para seguimiento completo del proyecto, ver [BITACORA_KINGFISHER.md](BITACORA_KINGFISHER.md)**

## ğŸ¯ OBJETIVO TÃ‰CNICO ESPECÃFICO
```
PIPELINE REUTILIZABLE: DOCUMENTOS â†’ CHUNKING â†’ EMBEDDING â†’ ALMACENAMIENTO TRIPLE â†’ AGENTE A2A
```

---

## ğŸ—ï¸ **ARQUITECTURA TÃ‰CNICA IMPLEMENTADA**

### **ğŸ“¦ CORE MODULES COMPLETADOS**

#### **1. rag_preprocessing/core/**
```python
â”œâ”€â”€ triple_processor.py          # âœ… Pipeline principal
â”œâ”€â”€ embedding_manager.py         # âœ… GestiÃ³n de embeddings
â”œâ”€â”€ smart_chunker.py            # âš ï¸ Performance optimization
â”œâ”€â”€ enhanced_triple_processor.py # âš ï¸ Performance optimization
â””â”€â”€ embedding_types.py          # âœ… Type definitions
```

#### **2. rag_preprocessing/storage/**
```python
â”œâ”€â”€ vector_store.py             # âœ… ChromaDB integration
â”œâ”€â”€ graph_store.py              # âœ… NetworkX + spaCy
â”œâ”€â”€ metadata_store.py           # âœ… SQLite integration
â””â”€â”€ hybrid_vector_store.py      # âš ï¸ Performance optimization
```

#### **3. agents/**
```python
â”œâ”€â”€ kingfisher_agent.py         # âœ… Main A2A agent
â”œâ”€â”€ kingfisher_agent_performance.py # âš ï¸ Performance variant
â”œâ”€â”€ protocol/
â”‚   â”œâ”€â”€ agent_card.py           # âœ… A2A discovery
â”‚   â””â”€â”€ task_manager.py         # âœ… LangGraph workflow
â””â”€â”€ server/
    â”œâ”€â”€ a2a_server.py           # âœ… Production server
    â””â”€â”€ a2a_performance_server.py # âŒ Dependency conflicts
```

---

## ğŸ”§ **IMPLEMENTACIÃ“N TÃ‰CNICA DETALLADA**

### **âœ… TRIPLE STORAGE PIPELINE (COMPLETADO)**

#### **Vector Storage (ChromaDB)**
```python
# ConfiguraciÃ³n actual exitosa
COLLECTION_NAME = "kingfisher_documents"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"  # 384 dimensions
CHUNK_SIZE = 500  # Optimizado para context
CHUNK_OVERLAP = 50  # 10% overlap
```

#### **Graph Storage (NetworkX + spaCy)**
```python
# ConfiguraciÃ³n actual exitosa
NLP_MODEL = "es_core_news_sm"  # Spanish language model
ENTITY_TYPES = ["PERSON", "ORG", "GPE", "PRODUCT", "EVENT"]
RELATIONSHIP_EXTRACTION = "dependency_parsing"  # spaCy dep trees
COMMUNITY_ALGORITHM = "leiden"  # Superior to Louvain
```

#### **Metadata Storage (SQLite)**
```python
# Schema implementado
TABLES = {
    "documents": ["id", "title", "content", "timestamp", "source"],
    "chunks": ["id", "document_id", "content", "vector_id", "position"],
    "entities": ["id", "text", "label", "document_id", "start", "end"],
    "relationships": ["id", "source", "target", "relation", "document_id"]
}
```

### **âœ… GOOGLE A2A PROTOCOL (COMPLETADO)**

#### **Agent Card Specification**
```json
{
  "name": "Kingfisher RAG Agent",
  "version": "1.0.0",
  "provider": {"name": "Kingfisher", "url": "http://localhost:8000"},
  "skills": [
    {
      "name": "process_documents",
      "description": "Process documents through triple storage pipeline",
      "parameters": {
        "content": {"type": "string", "required": true},
        "processing_mode": {"type": "string", "enum": ["VECTOR_ONLY", "GRAPH_ONLY", "TRIPLE_FULL"]}
      }
    },
    {
      "name": "retrieve_knowledge", 
      "description": "Retrieve information using hybrid search",
      "parameters": {
        "query": {"type": "string", "required": true},
        "search_type": {"type": "string", "enum": ["vector", "graph", "hybrid"]}
      }
    },
    {
      "name": "analyze_metadata",
      "description": "Analyze document metadata and relationships", 
      "parameters": {
        "document_id": {"type": "string", "required": true}
      }
    }
  ]
}
```

#### **LangGraph Workflow Implementation**
```python
# Estado exitoso del workflow
WORKFLOW_NODES = {
    "route_task": "Determinar tipo de skill solicitada",
    "process_documents": "Ejecutar pipeline triple storage", 
    "retrieve_knowledge": "BÃºsqueda hÃ­brida vector+graph",
    "analyze_metadata": "AnÃ¡lisis relacional metadatos",
    "complete_task": "Finalizar y retornar resultado"
}

WORKFLOW_EDGES = {
    START â†’ "route_task",
    "route_task" â†’ ["process_documents", "retrieve_knowledge", "analyze_metadata"],
    ["process_documents", "retrieve_knowledge", "analyze_metadata"] â†’ "complete_task",
    "complete_task" â†’ END
}
```

---

## âš ï¸ **PROBLEMAS TÃ‰CNICOS CRÃTICOS IDENTIFICADOS**

### **ğŸš¨ DEPENDENCY CONFLICTS (BLOQUEANTE)**

#### **Conflicto NumPy/SciPy**
```
ERROR: numpy.dtype size changed, may indicate binary incompatibility
Expected 96 from C header, got 88 from PyObject

CAUSA: 
- NumPy version: 2.3.0 (installed)
- SciPy requirement: NumPy >=1.22.4 and <1.29.0
- Binary incompatibility between versions

IMPACTO:
- Performance server no puede iniciar
- Smart chunker + NLTK + SciPy chain fails
- Advanced performance features blocked
```

#### **Import Chain Issues**
```python
# Cadena de imports problemÃ¡tica
smart_chunker.py â†’ nltk â†’ scipy.stats â†’ scipy.spatial â†’ numpy (binary conflict)

SOLUCION INMEDIATA:
pip install numpy==1.26.4 --force-reinstall
pip install scipy==1.12.0 --upgrade
```

### **ğŸ”§ ASYNC/SYNC MISMATCH**
```python
# Error en kingfisher_agent_performance.py
await self.task_manager.update_task_status(task_id, status)
#     ^^^^^^^^^^^^^^^^^ No es async function

FIX:
self.task_manager.update_task_status(task_id, status)  # Sin await
```

---

## ğŸ¯ **ESTRATEGIA DE RESOLUCIÃ“N INMEDIATA**

### **PASO 1: Environment Fix (5 min)**
```bash
# En PowerShell
.\venv\Scripts\activate

# Fix dependencies 
pip install numpy==1.26.4 --force-reinstall
pip install scipy==1.12.0 --upgrade

# Verificar compatibilidad
python -c "import numpy; import scipy; print('OK')"
```

### **PASO 2: Code Fix (10 min)**
```python
# En kingfisher_agent_performance.py lÃ­nea ~87
# CAMBIAR:
await self.task_manager.update_task_status(task_id, TaskStatus.COMPLETED)

# POR:
self.task_manager.update_task_status(task_id, TaskStatus.COMPLETED)
```

### **PASO 3: Validation Test (5 min)**
```bash
# Test performance server
uvicorn agents.server.a2a_performance_server:app --host 0.0.0.0 --port 8001 --reload

# Verificar ambos servidores
curl http://localhost:8000/health  # Main server
curl http://localhost:8001/health  # Performance server
```

---

## ğŸ¯ **OBJETIVO TÃ‰CNICO INMEDIATO**

### **CRITERIO DE Ã‰XITO TÃ‰CNICO:**
```bash
âœ… Virtual environment activated
âœ… NumPy 1.26.4 + SciPy 1.12.0 compatible
âœ… Performance server starts successfully
âœ… Both servers (8000 + 8001) operational
âœ… 7/7 integration tests passing
âœ… All performance optimizations functional
```

### **ENTREGABLES TÃ‰CNICOS POST-FIX:**
1. **Performance benchmarks** documentados
2. **Smart chunker** operational
3. **Batch embedder** functional
4. **Hybrid retriever** tested
5. **Dual-server architecture** validated

---

## ğŸ“‹ **VALIDACIÃ“N TÃ‰CNICA FINAL**

### **Component Integration Test**
```python
# Test completo post-fix
from rag_preprocessing.core import TripleProcessor
from agents.kingfisher_agent_performance import KingfisherPerformanceAgent

# 1. Core functionality
processor = TripleProcessor()
result = await processor.process_document("test content")
assert result.success

# 2. Performance features  
agent = KingfisherPerformanceAgent()
task_result = await agent.process_task({"skill": "process_documents"})
assert task_result.status == "completed"

# 3. HTTP endpoints
import requests
response = requests.get("http://localhost:8001/health")
assert response.status_code == 200
```

---

**ğŸ¯ RESULTADO ESPERADO**: Pipeline RAG completo con performance optimizations funcional y listo para integraciÃ³n como componente reutilizable. 